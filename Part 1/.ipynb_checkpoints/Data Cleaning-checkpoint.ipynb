{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1effc3",
   "metadata": {},
   "source": [
    "# Data Cleaning Process Using Jupyter Lab\n",
    "Becuase the data I need is not publicly available in the format that I want it to be, I'll need to do some data gathering and cleaning on my own. This is completed in Python because I need to utilise several Python packages that is either too difficult or not available to use in R.\n",
    "\n",
    "Only data gathering and some basic cleaning is done here in python. Everything else will be done in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412fe3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some packages that we need to use\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b7570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "known_keywords = [\"DD\", \"YOLO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee9d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files and get posts on r/wsb\n",
    "wsb_df = pd.read_csv(\"/Users/daniel/Documents/Academics/Undergraduate/2021-22 Academic Year/Fall Session/STA302H1F/Final Project/Data/reddit_wsb.csv\")\n",
    "symbols = pd.read_csv(\"/Users/daniel/Documents/Academics/Undergraduate/2021-22 Academic Year/Fall Session/STA302H1F/Final Project/Data/stock_symbols.csv\")['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad7a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/y3hsjq0d7xn0284_58315lb40000gn/T/ipykernel_7019/1925042774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[word] = 0\n"
     ]
    }
   ],
   "source": [
    "# If post mentions a valid symbol, add it as a row into result_df\n",
    "for index, row in wsb_df.iterrows():\n",
    "    title = row[0]\n",
    "    for word in title.split(\" \"):\n",
    "        word = word.replace(\"$\", \"\")\n",
    "        if word in symbols and word not in known_keywords:\n",
    "            result_df[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb512113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [NEW, FOR, CAN, ME, AMC, AN, IS, NOK, GME, MOON, AG, JUST, HOLD, FIZZ, MOD, BB, RH, PLTR, SPY, YOU, OR, PT, EOD, AKA, IT, BIG, DD, HEAR, A, ALL, EVER, QQQ, LOVE, AWAY, AM, GOOD, TEAM, GO, ON, CRSR, POST, NAKD, ARE, SI, BE, SPCE, BEST, HJLI, BDR, EWZ, APP, STAR, PPL, RACE, AAL, SO, BY, TDOC, IPO, TELL, UP, F, NAK, OUT, ONE, MASS, SNDL, U, TD, GE, KOSS, COIN, GNUS, FUND, AMZN, NOW, APRN, SRNE, LIT, PTEN, NNDM, PAAS, HOPE, BBBY, LOW, ESGC, XSPA, OXY, MDVL, MOVE, Y, AA, APPS, WANT, FREE, HAS, ANY, FORM, OLD, DUDE, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 1314 columns]\n"
     ]
    }
   ],
   "source": [
    "pprint(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
